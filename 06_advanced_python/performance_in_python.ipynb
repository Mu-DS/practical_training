{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Asymptotic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big O Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big O - or $\\mathcal{O}(n)$ - refers to the <span style=\"text-decoration: underline\">*worst-case scaling*</span> with size $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All coefficients or smaller components are not to be included"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/1830/1*5ZLci3SuR0zM_QlZOADv8Q.jpeg\" width=640 />\n",
    "\n",
    "https://www.bigocheatsheet.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\mathcal{O}(N) + \\mathcal{O}(\\log N)  =  \\mathcal{O}(N + \\log N)  =  \\mathcal{O}(N) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big Theta Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big $\\Theta$ - or $\\mathcal{\\Theta}(n)$ - refers to the <span style=\"text-decoration: underline\">*average-case scaling*</span> with size $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Omega Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big $\\Omega$ - or $\\mathcal{\\Omega}(n)$ - refers to the <span style=\"text-decoration: underline\">*best-case scaling*</span> with size $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, these are simplified.\n",
    "\n",
    "For a deep dive into asymptotic analysis see: https://cathyatseneca.gitbooks.io/data-structures-and-algorithms/content/analysis/notations.html\n",
    "\n",
    "(it is also a great course on data structures and algorithms!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intrinsic Object Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Object Complexity\n",
    "\n",
    "https://wiki.python.org/moin/TimeComplexity\n",
    "\n",
    "https://www.ics.uci.edu/~pattis/ICS-33/lectures/complexitypython.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Operation        | Example      | Best or Average Case | Worst Case | Note                       |\n",
    "|------------------|--------------|--------------|----------------------|----------------------------|\n",
    "| Copy             | `l.copy()`     | O(n)         | O(n)                 | Same as l[:] which is O(N) |\n",
    "| Append           | `l.append(5)`  | O(1)         | O(1)                 | |\n",
    "| Pop last         | `l.pop()`      | O(1)         | O(1)                 | same as l.pop(-1), popping at end |\n",
    "| Pop intermediate | `l.pop(n-k)`   | O(k)         | O(k)                 | |\n",
    "| Pop first        | `l.pop(0)`     | O(n)         | O(n)                 | |\n",
    "| Insert           | `l[a:b] = ...` | O(n)         | O(n)                 | |\n",
    "| Get Item         | `l[i]`         | O(1)         | O(1)                 | |\n",
    "| Set Item         | `l[i] = 0`     | O(1)         | O(1)                 | |\n",
    "| Iteration        | `for v in l:`  | O(n)         | O(n)                 | |\n",
    "| Get Slice (k=b-a)| `l[a:b]`       | O(k)         | O(k)                 | `l[1:5]:O(l)/l[:]:O(len(l)-0)=O(N)` |\n",
    "| Del Slice (k=b-a)|              | O(n)         | O(n)                 | |\n",
    "| Delete Item      | `del l[i]`/`l.remove(a)` | O(n)         | O(n)                 | |\n",
    "| Set Slice        |              | O(k+n)       | O(k+n)               | |\n",
    "| Extend (by k)    | `l.extend(k)`  | O(len(k))    | O(len(k))            | depends only on len of extension |\n",
    "| Sort             | `l.sort()`     | O(n log n)   | O(n log n)           | key/reverse doesn't change this |\n",
    "| Multiply         | `k*l`        | O(nk)        | O(nk)                | `5*l is O(N): len(l)*l is O(N**2)` |\n",
    "| min(s), max(s)   | `min(l)/max(l)| O(n)         | O(n)                 | |\n",
    "| Get Length       | `len(l)`       | O(1)         | O(1)                 | |\n",
    "| Reverse          | `l.reverse()  | O(n)         | O(n)                 | |\n",
    "| Containment      | x `in`/`not in` l |         | O(n)                 | searches list |\n",
    "| Clear            | `l.clear()`    | O(1)         | similar to l = []    | Deferred garbage collection |\n",
    "| Construction     | `list(...)`    | O(n)         | O(n)                 | depends on length of argument\n",
    "| check `==`, `!=` | `l1 == l2`     | O(n)         |\n",
    "| Remove           | `l.remove(...)`|              | On)     | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Operation                           | Example      | Best or Average case          | Worst Case         | notes                                      |\n",
    "|-------------------------------------|--------------|-----------------------|--------------------|--------------------------------------------|\n",
    "| Containment                         | x in s       | O(1)                  | O(n)               | compare to list/tuple - O(n)               |\n",
    "| Length                              | len(s)       | O(1)                  | O(1)               |                                            |\n",
    "| Add                                 | s.add(a)     | O(1)                  | O(1)               |\n",
    "| Remove                              | s.remove(a)  | O(1)                  | O(1)               | compare to list/tuple - O(N)\n",
    "| Discard                             | s.discard(a) | O(1)                  | O(1)               | \n",
    "| Pop                                 | s.pop()      | O(1)                  | O(1)               | compare to list - O(N)\n",
    "| Clear                               | s.clear()    | O(1)                  | O(1)               | similar to s = set()\n",
    "| Construction                        | set(n)       | O(n)                  | O(n)               |\n",
    "| check ==, !=                        | s != t       | O(min(len(s),lent(t)) | O(n)               |\n",
    "| <=/<                                | s <= t       | O(len(s1))            | O(n)               | issubset \n",
    "| >=/>                                | s >= t       | O(len(s2))            | O(n)               | issuperset s <= t == t >= s\n",
    "| Union                               | `s | t`      | O(len(s)+len(t))      | O(len(s)+len(t))   |                                            |\n",
    "| Intersection                        | `s & t`      | O(min(len(s), lent(t))| O(len(s) * len(t)) | replace \"min\" with \"max\" if t is not a set |\n",
    "| Multiple intersection               | `s1&s2&..&sn`|                       | `(n-1)*O(l)`       | l is max(len(s1),..,len(sn))               |\n",
    "| Difference                          | s - t        |                       | O(len(t))          |                    |                                            |\n",
    "| Symmetric Diff                      | s ^ t        | O(len(s))             | O(len(s) * len(t)) |   \n",
    "| Iteration                           | for v in s:  | O(N)                  |\n",
    "| Copy                                | s.copy()     | O(N)                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Operation    | Example                | Average Case | Amortized Worst Case |\t \n",
    "| -------------|------------------------|--------------|----------------------| \n",
    "| Copy         | `d.copy()`             | O(n)         | O(n)                 |\n",
    "| Get Item     | `d[k]`                 | O(1)         | O(n)                 |\n",
    "| Set Item     | `d[k]=v`               | O(1)         | O(n)                 |\n",
    "| Delete Item  | `del d[k]`             | O(1)         | O(n)                 |\n",
    "| Iteration    | `for k,v in d.items()` | O(n)         | O(n)                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operation     | Example      | Class         | Notes\n",
    "--------------|--------------|---------------|------------------------------\n",
    "Index         | d[k]         | O(1)      |\n",
    "Store         | d[k] = v     | O(1)      |\n",
    "Length        | len(d)       | O(1)      |\n",
    "Delete        | del d[k]     | O(1)      |\n",
    "get/setdefault| d.get(k)     | O(1)      |\n",
    "Pop           | d.pop(k)     | O(1)      | \n",
    "Pop item      | d.popitem()  | O(1)      | popped item \"randomly\" selected\n",
    "Clear         | d.clear()    | O(1)      | similar to s = {} or = dict()\n",
    "View          | d.keys()     | O(1)      | same for d.values()\n",
    "--------------|--------------|-----------|\n",
    "Construction  | dict(...)    | O(len(...))   | depends # (key,value) 2-tuples\n",
    "\n",
    "Iteration     | for k in d:  | O(N)          | all forms: keys, values, items\n",
    "\t      \t      \t       \t\t     | Worst: no return/break in loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Parallel Programming in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limits of Comprehension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List & Dict comprehensions are great and fast, however, require a lot of memory overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311 ms ± 27.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "a = []\n",
    "for i in range(n):\n",
    "    a.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183 ms ± 10.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "a = [i for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363 ms ± 51.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "a = np.empty(n)\n",
    "for i in range(n):\n",
    "    a[i] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257 ms ± 17 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit a = np.empty(n)\n",
    "for i in range(n):\n",
    "    a[i] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288 ms ± 24.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit a = np.empty(n, dtype=np.int)\n",
    "for i in range(n):\n",
    "    a[i] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit, prange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def assign(a, n):\n",
    "    for i in range(n):\n",
    "        a[i] = i\n",
    "    return a\n",
    "a = np.empty(n, dtype=np.int)\n",
    "a = assign(a, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641 µs ± 73.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit a = np.empty(n, dtype=np.int)\n",
    "assign(a, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def assign(a, n):\n",
    "    for i in prange(n):\n",
    "        a[i] = i\n",
    "    return a\n",
    "a = np.empty(n, dtype=np.int)\n",
    "a = assign(a, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "933 µs ± 78.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit a = np.empty(n, dtype=np.int)\n",
    "assign(a, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def assign(n):\n",
    "    a = np.empty(n)\n",
    "    for i in prange(n):\n",
    "        a[i] = i\n",
    "    return a\n",
    "a = assign(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.44 ms ± 188 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "assign(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True, nogil=True, parallel=True)\n",
    "def assign(a, n):\n",
    "    for i in prange(n):\n",
    "        a[i] = i\n",
    "    return a\n",
    "a = np.empty(n, dtype=np.int)\n",
    "a = assign(a, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541 µs ± 66 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit a = np.empty(n, dtype=np.int)\n",
    "assign(a, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Type            | Python Module      | Switch between | #Processes |\n",
    "|-----------------|--------------------|----------------|------------|\n",
    "| Multi-Threading |$\\texttt{threading}$| OS decides     | 1          |\n",
    "| Asynchronous    |$\\texttt{asyncio}  $| tasks decide   | 1          |\n",
    "| Multi-Processing|$\\texttt{multiprocessing}$| None (Parallel)| Many |\n",
    "| Multi-Nodes     |$\\texttt{dask}$     | None           | Many Nodes |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AsyncIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Core Library: https://docs.python.org/3/library/asyncio.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is asynchronous programming different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synchronous programming:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Every event happens after the previos one: one at a time, one after the other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asynchronous programming:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Return immediately to do other things while waiting for the event to finish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Getting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Steps:\n",
    "  1. formulate request\n",
    "  2. send request\n",
    "  3. wait for reply/data\n",
    "  4. get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In synchronous programming, until Step 4 happens, nothing else can be done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In asynchronous programming, after Step 2, the resources (e.g. Kernel/Processor) can be used for other tasks until data comes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous programming in context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions to skip:\n",
    "\n",
    "- What is concurrency?\n",
    "- How does it differ from parallelism?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asynchronous programming falls under **concurrent** programming.\n",
    "\n",
    "**concurrency**: multiple operations **able to run** at the same time\n",
    "\n",
    "While variables are not yet assigned values, they are often called \\texttt{Futures}, since their value is assigned in the future. That is, the set of operations that is determining the value have not yet been fully processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concurrency as the ability to separate into parallel operations, does not imply that they are in fact processed in parallel. That property is called parallelism. The distinction is important, since e.g. a matrix addition might have a high degree of concurrency (each addition could be doen in parallel), but doing all of these actually in parallel is a not efficient or even possible. \n",
    "\n",
    "This means: degree of parallelism $\\leq$ degree of concurrency.\n",
    "\n",
    "**parallelism**: multiple operations **running** at the same time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions to skip:\n",
    "\n",
    "- What is a thread?\n",
    "- How does it differ from a process?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thread\n",
    "\n",
    "thread: \"smallest sequence of programmed instructions that can be managed independently by a scheduler,\" typically as part of the operating system\n",
    "\n",
    "  - there can be multiple threads in a process\n",
    "  - each thread can be executed independently (and possibly in parallel) within the process\n",
    "  - In Python: threading module\n",
    "  - https://realpython.com/intro-to-python-threading/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- multiprocessing:\n",
    "  - In Python multiprocessing module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expensive_vec(array):\n",
    "    return np.log10(np.cumsum(np.sqrt(np.cumsum(np.exp2(np.log(np.sqrt(array)))+np.exp(np.log10(np.cbrt(array))))))/np.exp(np.log10(np.cbrt(array))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = [np.random.random()*1000000 for _ in range(1000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.31 s ± 114 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "expensive_vec(d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-2bfe3bca8ee5>:1: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"expensive_vec_nb\" failed type inference due to: \u001b[1m\u001b[1m\u001b[1mNo implementation of function Function(<ufunc 'sqrt'>) found for signature:\n",
      " \n",
      " >>> sqrt(reflected list(float64))\n",
      " \n",
      "There are 2 candidate implementations:\n",
      "\u001b[1m  - Of which 2 did not match due to:\n",
      "  Overload in function 'Numpy_rules_ufunc.generic': File: numba\\core\\typing\\npydecl.py: Line 100.\n",
      "    With argument(s): '(reflected list(float64))':\u001b[0m\n",
      "\u001b[1m   Rejected as the implementation raised a specific error:\n",
      "     TypingError: \u001b[1mcan't resolve ufunc sqrt for types (reflected list(float64),)\u001b[0m\u001b[0m\n",
      "  raised from C:\\Users\\rgrei\\AppData\\Roaming\\Python\\Python37\\site-packages\\numba\\core\\typing\\npydecl.py:106\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: resolving callee type: Function(<ufunc 'sqrt'>)\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of call at <ipython-input-42-2bfe3bca8ee5> (3)\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-42-2bfe3bca8ee5>\", line 3:\u001b[0m\n",
      "\u001b[1mdef expensive_vec_nb(array):\n",
      "\u001b[1m    return np.log10(np.cumsum(np.sqrt(np.cumsum(np.exp2(np.log(np.sqrt(array)))+np.exp(np.log10(np.cbrt(array))))))/np.exp(np.log10(np.cbrt(array))))\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "C:\\Users\\rgrei\\AppData\\Roaming\\Python\\Python37\\site-packages\\numba\\core\\object_mode_passes.py:178: NumbaWarning: \u001b[1mFunction \"expensive_vec_nb\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"<ipython-input-42-2bfe3bca8ee5>\", line 2:\u001b[0m\n",
      "\u001b[1m@jit\n",
      "\u001b[1mdef expensive_vec_nb(array):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "C:\\Users\\rgrei\\AppData\\Roaming\\Python\\Python37\\site-packages\\numba\\core\\object_mode_passes.py:188: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"<ipython-input-42-2bfe3bca8ee5>\", line 2:\u001b[0m\n",
      "\u001b[1m@jit\n",
      "\u001b[1mdef expensive_vec_nb(array):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n"
     ]
    }
   ],
   "source": [
    "@jit\n",
    "def expensive_vec_nb(array):\n",
    "    return np.log10(np.cumsum(np.sqrt(np.cumsum(np.exp2(np.log(np.sqrt(array)))+np.exp(np.log10(np.cbrt(array))))))/np.exp(np.log10(np.cbrt(array))))\n",
    "_ = expensive_vec_nb(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.29 s ± 261 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "expensive_vec_nb(d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Wall time: 68 ms\n",
      "hi\n",
      "Wall time: 515 ms\n"
     ]
    }
   ],
   "source": [
    "# creating a thread\n",
    "%time x = threading.Thread(target=expensive_vec, args=([d1]))\n",
    "# running a thread\n",
    "%time x.start()\n",
    "print(\"hi\")\n",
    "# waiting for the thread to finish\n",
    "%time x.join()\n",
    "# done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "threading.Thread"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = [d1[i:i*len(d1)//5].copy() for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with Pool(5) as p:\n",
    "    _ = p.map(expensive_vec, chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### All do the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_processes = 2\n",
    "client = Client(processes=n_processes,\n",
    "                threads_per_worker=2,\n",
    "                n_workers=n_processes,\n",
    "                memory_limit='{}GB'.format(int(n_processes*2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.36 s\n",
      "Wall time: 15.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "big_futures = client.scatter(chunks)\n",
    "futures = client.submit(expensive_vec, big_futures)\n",
    "%time bootstrap_results = np.array([fut.result() for fut in big_futures])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.cancel(futures)\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rgrei\\Anaconda3\\envs\\py38\\lib\\site-packages\\distributed\\worker.py:3373: UserWarning: Large object of size 1.80 MB detected in task graph: \n",
      "  ([248797.93748180202, 647650.4325437869, 291136.24 ... .23489052575],)\n",
      "Consider scattering large objects ahead of time\n",
      "with client.scatter to reduce scheduler burden and \n",
      "keep data on workers\n",
      "\n",
      "    future = client.submit(func, big_data)    # bad\n",
      "\n",
      "    big_future = client.scatter(big_data)     # good\n",
      "    future = client.submit(func, big_future)  # good\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 47.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "futures = client.map(expensive_vec, chunks)\n",
    "bootstrap_results = np.array([fut.result() for fut in futures])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with parallel_backend('dask'):\n",
    "def proc(i):\n",
    "    # Your normal scikit-learn code here\n",
    "    from astroML.correlation import two_point_angular\n",
    "    if i > 0:\n",
    "        sample = np.sort(np.random.randint(0, len(x_dat), len(x_dat)))\n",
    "    else:\n",
    "        sample = range(len(x_dat))\n",
    "    x_sample = x_dat[sample]\n",
    "    y_sample = y_dat[sample]\n",
    "    bins = 10 ** np.linspace(np.log10(1/50000.), np.log10(0.5), 300)\n",
    "    bin_centers = 0.5 * (bins[1:] + bins[:-1])\n",
    "    res = two_point_angular(x_sample, y_sample, bins=bins, method='landy-szalay')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futures = client.map(proc, range(n_bootstraps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_results = np.array([fut.result() for fut in futures])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.cancel(futures)\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split workload across"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointers in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pass by Value vs Pass by Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULTS = {\"mode\": \"NUMPY\", \"step_size\": 1e-3, \"steps\": 1e4, \"grid_size\": 128, \"k0\": 0.15, \"N\": 3, \"nu\": 1e-6, \"c1\": 1, \"kappa\": 1, \"arakawa_coeff\": 1, \"out\": \"\", \"in\": \"\", \"snaps\": 1000, \"seed\": None}\n",
    "def get_params(in_path):\n",
    "    parameters = DEFAULTS\n",
    "    context = json.load(open(f\"{in_path}/src/context.json\", \"r\"))\n",
    "    for key, value in context.items():\n",
    "        parameters[key] = value\n",
    "    parameters['sim_number'] = int(in_path.split('_')[-1])\n",
    "    return parameters\n",
    "\n",
    "sim_directory = [get_params(f\"/ptmp/rccg/sim_{sim:06}\") for sim in sim_nums]\n",
    "print(len(np.unique(sim_nums)))\n",
    "print(len(np.unique([sim['sim_number'] for sim in sim_directory])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULTS = {\"mode\": \"NUMPY\", \"step_size\": 1e-3, \"steps\": 1e4, \"grid_size\": 128, \"k0\": 0.15, \"N\": 3, \"nu\": 1e-6, \"c1\": 1, \"kappa\": 1, \"arakawa_coeff\": 1, \"out\": \"\", \"in\": \"\", \"snaps\": 1000, \"seed\": None}\n",
    "def get_params(in_path):\n",
    "    parameters = DEFAULTS.copy()\n",
    "    context = json.load(open(f\"{in_path}/src/context.json\", \"r\"))\n",
    "    for key, value in context.items():\n",
    "        parameters[key] = value\n",
    "    parameters['sim_number'] = int(in_path.split('_')[-1])\n",
    "    return parameters\n",
    "\n",
    "sim_directory = [get_params(f\"/ptmp/rccg/sim_{sim:06}\") for sim in sim_nums]\n",
    "print(len(np.unique(sim_nums)))\n",
    "print(len(np.unique([sim['sim_number'] for sim in sim_directory])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-py38]",
   "language": "python",
   "name": "conda-env-anaconda3-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
